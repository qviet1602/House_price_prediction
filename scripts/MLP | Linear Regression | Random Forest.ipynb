{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'postgresql://{user}:{passwd}@{host}:{port}/{db}'.format(\n",
    "         user=\"cse6242\", passwd=\"cse6242\", host=\"localhost\", port=5432, db=\"cse6242\")\n",
    "\n",
    "engine = create_engine(url, pool_size=50)\n",
    "\n",
    "engine.connect()\n",
    "connection = engine.connect() \n",
    "query = \"SELECT county_id, home_type_id, year_month, index_value from county_timeseries\"\n",
    "\n",
    "df = pd.read_sql(query, con=connection)\n",
    "\n",
    "df.rename(columns = {'year_month':'year'}, inplace = True)\n",
    "df[['year','month']] = df['year'].str.split('-',expand=True)\n",
    "\n",
    "cols = df.columns.tolist() \n",
    "new_cols = [x for x in cols if x != cols[-2]] + [cols[-2]]\n",
    "df = df[new_cols]\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.fillna(method=\"bfill\", inplace=True)\n",
    "random_state = 100\n",
    "X_DATA = x_data = df.loc[:, df.columns != \"index_value\"]\n",
    "Y_DATA = y_data = Y_TRAIN_ALL_VALS = df.loc[:, \"index_value\"]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, shuffle=True, random_state=random_state)\n",
    "\n",
    "# _, _, Y_TRAIN_ALL_VALS, _ = train_test_split(x_data, y_data, test_size=0.1, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          117500.0\n",
       "1          117200.0\n",
       "2          116500.0\n",
       "3          115500.0\n",
       "4          114600.0\n",
       "             ...   \n",
       "2327623    121100.0\n",
       "2327624    120700.0\n",
       "2327625    120000.0\n",
       "2327626    119200.0\n",
       "2327627    118300.0\n",
       "Name: index_value, Length: 2327628, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TRAIN_ALL_VALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.predict(X_TEST[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'postgresql://{user}:{passwd}@{host}:{port}/{db}'.format(\n",
    "         user=\"cse6242\", passwd=\"cse6242\", host=\"localhost\", port=5432, db=\"cse6242\")\n",
    "\n",
    "engine = create_engine(url, pool_size=50)\n",
    "\n",
    "engine.connect()\n",
    "connection = engine.connect() \n",
    "query = \"SELECT county_id, home_type_id, year_month, index_value from county_timeseries LIMIT 300000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_df, test_y_df = pd.DataFrame(), pd.DataFrame()\n",
    "train_x_df, train_y_df = pd.DataFrame(), pd.DataFrame()\n",
    "clf= MLPClassifier(hidden_layer_sizes=(10,), activation='logistic',\n",
    "                       solver='adam',verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 9.62393330\n",
      "Iteration 2, loss = 9.60460938\n",
      "Iteration 3, loss = 9.58499158\n",
      "Iteration 4, loss = 9.57117703\n",
      "Iteration 5, loss = 9.57935614\n",
      "Iteration 6, loss = 9.51268845\n",
      "Iteration 7, loss = 9.48206366\n",
      "Iteration 8, loss = 9.45424453\n",
      "Iteration 9, loss = 9.48140353\n",
      "Iteration 10, loss = 9.58827829\n",
      "Iteration 11, loss = 9.40167785\n",
      "Iteration 12, loss = 9.37352939\n",
      "Iteration 13, loss = 9.31125133\n",
      "Iteration 14, loss = 9.44361280\n",
      "Iteration 15, loss = 9.28719759\n",
      "Iteration 16, loss = 9.22776048\n",
      "Iteration 17, loss = 9.17036088\n",
      "Iteration 18, loss = 9.39901996\n",
      "Iteration 19, loss = 9.27977224\n",
      "Iteration 20, loss = 9.27296997\n",
      "Iteration 21, loss = 9.19350830\n",
      "Iteration 22, loss = 9.03619367\n",
      "Iteration 23, loss = 9.07205255\n",
      "Iteration 24, loss = 8.96577002\n",
      "Iteration 25, loss = 9.35300115\n",
      "Iteration 26, loss = 9.10718501\n",
      "Iteration 27, loss = 9.07500451\n",
      "Iteration 28, loss = 9.11016677\n",
      "Iteration 29, loss = 9.25978968\n",
      "Iteration 30, loss = 9.02967407\n",
      "Iteration 31, loss = 8.91827974\n",
      "Iteration 32, loss = 8.81433993\n",
      "Iteration 33, loss = 8.83233128\n",
      "Iteration 34, loss = 8.74446469\n",
      "Iteration 35, loss = 8.87313952\n",
      "Iteration 36, loss = 8.86236570\n",
      "Iteration 37, loss = 8.96426559\n",
      "Iteration 38, loss = 8.88906218\n",
      "Iteration 39, loss = 8.81095611\n",
      "Iteration 40, loss = 8.69482195\n",
      "Iteration 41, loss = 8.64414235\n",
      "Iteration 42, loss = 8.77028359\n",
      "Iteration 43, loss = 8.48284824\n",
      "Iteration 44, loss = 8.44368955\n",
      "Iteration 45, loss = 8.55324500\n",
      "Iteration 46, loss = 8.53195078\n",
      "Iteration 47, loss = 8.47941875\n",
      "Iteration 48, loss = 8.74512413\n",
      "Iteration 49, loss = 8.44065183\n",
      "Iteration 50, loss = 8.40063417\n",
      "Iteration 51, loss = 8.54676809\n",
      "Iteration 52, loss = 8.64771366\n",
      "Iteration 53, loss = 8.80606846\n",
      "Iteration 54, loss = 8.51898532\n",
      "Iteration 55, loss = 8.33006562\n",
      "Iteration 56, loss = 8.49272109\n",
      "Iteration 57, loss = 8.77813163\n",
      "Iteration 58, loss = 8.31443185\n",
      "Iteration 59, loss = 8.72489197\n",
      "Iteration 60, loss = 8.51201084\n",
      "Iteration 61, loss = 8.25506730\n",
      "Iteration 62, loss = 8.21248108\n",
      "Iteration 63, loss = 8.42625113\n",
      "Iteration 64, loss = 8.68551409\n",
      "Iteration 65, loss = 8.29561975\n",
      "Iteration 66, loss = 8.19515194\n",
      "Iteration 67, loss = 8.14141310\n",
      "Iteration 68, loss = 8.41149510\n",
      "Iteration 69, loss = 8.06783909\n",
      "Iteration 70, loss = 9.13920215\n",
      "Iteration 71, loss = 8.37667587\n",
      "Iteration 72, loss = 8.15238140\n",
      "Iteration 73, loss = 8.32138451\n",
      "Iteration 74, loss = 8.48582178\n",
      "Iteration 75, loss = 8.18206863\n",
      "Iteration 76, loss = 8.48417888\n",
      "Iteration 77, loss = 8.61747268\n",
      "Iteration 78, loss = 8.38173401\n",
      "Iteration 79, loss = 7.91377705\n",
      "Iteration 80, loss = 8.29895934\n",
      "Iteration 81, loss = 7.91905368\n",
      "Iteration 82, loss = 8.54952659\n",
      "Iteration 83, loss = 7.87572692\n",
      "Iteration 84, loss = 8.17122984\n",
      "Iteration 85, loss = 7.76907076\n",
      "Iteration 86, loss = 8.20054391\n",
      "Iteration 87, loss = 8.24633264\n",
      "Iteration 88, loss = 7.87069081\n",
      "Iteration 89, loss = 8.34693985\n",
      "Iteration 90, loss = 8.11304812\n",
      "Iteration 91, loss = 8.33410294\n",
      "Iteration 92, loss = 8.25999599\n",
      "Iteration 93, loss = 7.87836757\n",
      "Iteration 94, loss = 7.98969044\n",
      "Iteration 95, loss = 8.12333498\n",
      "Iteration 96, loss = 8.15046235\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 97, loss = 8.09358938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 98, loss = 7.66406902\n",
      "Iteration 99, loss = 8.15246545\n",
      "Iteration 100, loss = 8.06405311\n",
      "Iteration 101, loss = 7.63790601\n",
      "Iteration 102, loss = 7.85169579\n",
      "Iteration 103, loss = 7.86063139\n",
      "Iteration 104, loss = 7.73086792\n",
      "Iteration 105, loss = 8.47273464\n",
      "Iteration 106, loss = 8.67457882\n",
      "Iteration 107, loss = 7.67337152\n",
      "Iteration 108, loss = 7.73351294\n",
      "Iteration 109, loss = 8.20682455\n",
      "Iteration 110, loss = 7.96096465\n",
      "Iteration 111, loss = 8.17473427\n",
      "Iteration 112, loss = 8.14165532\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 113, loss = 8.80039215\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 114, loss = 7.60997507\n",
      "Iteration 115, loss = 7.56618313\n",
      "Iteration 116, loss = 7.52672239\n",
      "Iteration 117, loss = 7.83467091\n",
      "Iteration 118, loss = 8.54786449\n",
      "Iteration 119, loss = 7.55814494\n",
      "Iteration 120, loss = 8.96830084\n",
      "Iteration 121, loss = 7.83985717\n",
      "Iteration 122, loss = 7.99685785\n",
      "Iteration 123, loss = 7.38710955\n",
      "Iteration 124, loss = 8.46274646\n",
      "Iteration 125, loss = 7.47801708\n",
      "Iteration 126, loss = 7.91488582\n",
      "Iteration 127, loss = 8.30832156\n",
      "Iteration 128, loss = 8.16593446\n",
      "Iteration 129, loss = 8.40075305\n",
      "Iteration 130, loss = 7.68813001\n",
      "Iteration 131, loss = 7.58200869\n",
      "Iteration 132, loss = 7.36954733\n",
      "Iteration 133, loss = 7.63461676\n",
      "Iteration 134, loss = 8.07892773\n",
      "Iteration 135, loss = 8.09066497\n",
      "Iteration 136, loss = 8.35041750\n",
      "Iteration 137, loss = 7.74780056\n",
      "Iteration 138, loss = 8.07338911\n",
      "Iteration 139, loss = 7.92314387\n",
      "Iteration 140, loss = 7.77388038\n",
      "Iteration 141, loss = 7.60641174\n",
      "Iteration 142, loss = 7.33649288\n",
      "Iteration 143, loss = 7.47907743\n",
      "Iteration 144, loss = 7.61858266\n",
      "Iteration 145, loss = 7.23310138\n",
      "Iteration 146, loss = 7.79205834\n",
      "Iteration 147, loss = 7.63676992\n",
      "Iteration 148, loss = 7.62660076\n",
      "Iteration 149, loss = 7.50492889\n",
      "Iteration 150, loss = 7.65775661\n",
      "Iteration 151, loss = 8.52944773\n",
      "Iteration 152, loss = 7.61421757\n",
      "Iteration 153, loss = 7.87760030\n",
      "Iteration 154, loss = 8.19143707\n",
      "Iteration 155, loss = 7.35957105\n",
      "Iteration 156, loss = 7.61689022\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 157, loss = 7.47386983\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 158, loss = 7.71066987\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 159, loss = 7.38828697\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 160, loss = 7.45254817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 161, loss = 7.00847834\n",
      "Iteration 162, loss = 7.52257244\n",
      "Iteration 163, loss = 7.45833759\n",
      "Iteration 164, loss = 7.53297904\n",
      "Iteration 165, loss = 8.20015197\n",
      "Iteration 166, loss = 8.63147234\n",
      "Iteration 167, loss = 9.31550503\n",
      "Iteration 168, loss = 8.88674194\n",
      "Iteration 169, loss = 8.71062273\n",
      "Iteration 170, loss = 8.73294982\n",
      "Iteration 171, loss = 9.45211668\n",
      "Iteration 172, loss = 8.86503911\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 173, loss = 8.45019551\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 174, loss = 8.38309736\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 175, loss = 8.73385391\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 176, loss = 8.45392542\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 177, loss = 8.69135065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 178, loss = 8.44338301\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 179, loss = 8.47967753\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 180, loss = 8.37652442\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 181, loss = 8.21288302\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 182, loss = 8.65892380\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 183, loss = 8.75859957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 184, loss = 8.36788093\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 185, loss = 8.60884000\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 186, loss = 8.71869138\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 187, loss = 8.76266707\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 188, loss = 8.22890725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 189, loss = 8.64585369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 190, loss = 8.64675178\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 191, loss = 8.33350424\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 192, loss = 8.21661632\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 193, loss = 8.54515448\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 194, loss = 8.19829670\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 195, loss = 8.05982035\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 196, loss = 8.36738293\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 197, loss = 8.15090512\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 198, loss = 8.17505562\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 199, loss = 8.42367475\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 200, loss = 8.26601753\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 201, loss = 8.42187493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 202, loss = 8.44422464\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 203, loss = 7.98811072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 204, loss = 7.94930244\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 205, loss = 8.14671589\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 206, loss = 7.89607321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 207, loss = 8.66229779\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 208, loss = 8.74271815\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 209, loss = 8.14297345\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 210, loss = 8.10090718\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 211, loss = 7.91920034\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 212, loss = 8.01881720\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 213, loss = 8.05295554\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 214, loss = 8.58153939\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 215, loss = 7.95157115\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 216, loss = 8.31559087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 217, loss = 7.93701576\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 218, loss = 8.35561608\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 219, loss = 8.11974878\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 220, loss = 8.16485291\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 221, loss = 8.07267910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 222, loss = 8.03246526\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 223, loss = 8.07777696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 224, loss = 7.80337407\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 225, loss = 7.79038091\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 226, loss = 8.23660657\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 227, loss = 7.72458213\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 228, loss = 8.36268256\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 229, loss = 8.60969929\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 230, loss = 8.10389786\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 231, loss = 7.91123720\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 232, loss = 7.73927308\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 233, loss = 7.83705383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 234, loss = 7.74383207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 235, loss = 8.24968704\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 236, loss = 7.84778846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 237, loss = 8.31596935\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 238, loss = 7.82005286\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 239, loss = 7.51704831\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 240, loss = 8.02087434\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 241, loss = 7.61050891\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 242, loss = 7.82696811\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 243, loss = 8.66147868\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 244, loss = 8.04497374\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 245, loss = 7.92681197\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 246, loss = 7.71250884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 247, loss = 7.58530888\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 248, loss = 7.57594133\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 249, loss = 7.93561893\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 250, loss = 7.62603863\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 251, loss = 7.66648558\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 252, loss = 7.77930387\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 253, loss = 7.49430072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 254, loss = 7.70774070\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 255, loss = 7.68700389\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 256, loss = 8.11505413\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 257, loss = 7.57089467\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 258, loss = 7.47851072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 259, loss = 7.70648792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 260, loss = 7.55161470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 261, loss = 7.79644606\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 262, loss = 7.79784640\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 263, loss = 7.42476676\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 264, loss = 7.61295955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 265, loss = 8.41827744\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 266, loss = 7.53711802\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 267, loss = 7.72471250\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 268, loss = 8.18916107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 269, loss = 7.48177870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 270, loss = 7.41819731\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 271, loss = 7.42228093\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 272, loss = 7.70617390\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 273, loss = 7.47125162\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 274, loss = 7.57248334\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 275, loss = 7.53836086\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 276, loss = 7.70503683\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 277, loss = 7.58794460\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 278, loss = 7.37064323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 279, loss = 7.50973168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 280, loss = 7.43881409\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 281, loss = 7.37748186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 282, loss = 8.04367070\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 283, loss = 8.36070127\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 284, loss = 7.96950493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 285, loss = 7.94871015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 286, loss = 7.79524009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 287, loss = 8.05287361\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 288, loss = 7.57194114\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 289, loss = 7.55057412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 290, loss = 7.46897385\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 291, loss = 8.23213299\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 292, loss = 7.60462947\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 293, loss = 8.59124265\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 294, loss = 7.33851149\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 295, loss = 8.12214994\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 296, loss = 7.56026933\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 297, loss = 7.70233904\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 298, loss = 7.56127404\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 299, loss = 7.93342508\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 300, loss = 8.65266528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "for df in pd.read_sql(query, con=connection, chunksize=1000):\n",
    "    df.rename(columns = {'year_month':'year'}, inplace = True)\n",
    "    df[['year','month']] = df['year'].str.split('-',expand=True)\n",
    "    \n",
    "    cols = df.columns.tolist() \n",
    "    new_cols = [x for x in cols if x != cols[-2]] + [cols[-2]]\n",
    "    df = df[new_cols]\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    df.fillna(method=\"bfill\", inplace=True)\n",
    "    random_state = 100\n",
    "    x_data = df.loc[:, df.columns != \"index_value\"]\n",
    "    y_data = df.loc[:, \"index_value\"]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, shuffle=True, random_state=random_state)\n",
    "#     clf = MLPClassifier(solver='stochastic', alpha=1e-5,\n",
    "#                    hidden_layer_sizes=(6, 6), random_state=1, verbose=True)\n",
    "    train_x_df.append(x_train)\n",
    "    train_y_df.append(y_train)\n",
    "    test_x_df.append(x_test)\n",
    "    test_y_df.append(y_test)\n",
    "    \n",
    "    clf = clf.partial_fit(x_train, y_train,classes=np.unique(Y_TRAIN_ALL_VALS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9310512, 2327628)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_DATA.size, Y_DATA.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>08</td>\n",
       "      <td>319700</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>09</td>\n",
       "      <td>322300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>327800</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>330300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>334000</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>07</td>\n",
       "      <td>62800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>08</td>\n",
       "      <td>62400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>09</td>\n",
       "      <td>62300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>62300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>62400</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_id  home_type_id  year month  index_value   y_pred\n",
       "0          476             1  2017    08       319700  87300.0\n",
       "1          476             1  2017    09       322300  87300.0\n",
       "2          476             1  2017    10       327800  87300.0\n",
       "3          476             1  2017    11       330300  87300.0\n",
       "4          476             1  2017    12       334000  87300.0\n",
       "..         ...           ...   ...   ...          ...      ...\n",
       "995        480             1  2006    07        62800      NaN\n",
       "996        480             1  2006    08        62400      NaN\n",
       "997        480             1  2006    09        62300      NaN\n",
       "998        480             1  2006    10        62300  87300.0\n",
       "999        480             1  2006    11        62400  87300.0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_pred = clf.predict(x_train)\n",
    "#     print \"Score on training set: %0.8f\" % clf.score(train_input, train_target)\n",
    "#Testing the Neural Net\n",
    "\n",
    "# _, _, Y_TRAIN_ALL_VALS, _ = train_test_split(x_data, y_data, test_size=0.1, shuffle=True, random_state=random_state)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.25, shuffle=True, random_state=random_state)\n",
    "\n",
    "y_pred_train = clf.predict(x_train)\n",
    "# print(x_train)\n",
    "# print(y_pred)\n",
    "# print(y_train)\n",
    "y_hats_df = pd.DataFrame(data = y_pred_train, columns = ['y_pred'], index = x_train.index.copy())\n",
    "df_out_mlp_train = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(df_out_mlp_train)\n",
    "# 4. Compute score on testing set\n",
    "# print(clf.score(X_TEST, Y_TRAIN_ALL_VALS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_df = pd.DataFrame(data = y_pred_test, columns = ['y_pred'], index = x_test.index.copy())\n",
    "df_out_mlp_test = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>08</td>\n",
       "      <td>319700</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>09</td>\n",
       "      <td>322300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>327800</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>330300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>334000</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>07</td>\n",
       "      <td>62800</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>08</td>\n",
       "      <td>62400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>09</td>\n",
       "      <td>62300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>62300</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>62400</td>\n",
       "      <td>87300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_id  home_type_id  year month  index_value   y_pred\n",
       "0          476             1  2017    08       319700  87300.0\n",
       "1          476             1  2017    09       322300  87300.0\n",
       "2          476             1  2017    10       327800  87300.0\n",
       "3          476             1  2017    11       330300  87300.0\n",
       "4          476             1  2017    12       334000  87300.0\n",
       "..         ...           ...   ...   ...          ...      ...\n",
       "995        480             1  2006    07        62800  87300.0\n",
       "996        480             1  2006    08        62400      NaN\n",
       "997        480             1  2006    09        62300  87300.0\n",
       "998        480             1  2006    10        62300  87300.0\n",
       "999        480             1  2006    11        62400  87300.0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df_out = df_out_mlp_train['y_pred'].combine_first(df_out_mlp_test['y_pred'])\n",
    "\n",
    "# display(final_df_out)\n",
    "# \n",
    "\n",
    "y_hats_df = pd.DataFrame(data = final_df_out, columns = ['y_pred'], index = df.index.copy())\n",
    "# display(y_hats_df)\n",
    "final_df_out = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(final_df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163013.58604384927"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155651.48945709696"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'year_month':'year'}, inplace = True)\n",
    "df[['year','month']] = df['year'].str.split('-',expand=True)\n",
    "\n",
    "cols = df.columns.tolist() \n",
    "new_cols = [x for x in cols if x != cols[-2]] + [cols[-2]]\n",
    "df = df[new_cols]\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "x_data = df.loc[:, df.columns != \"index_value\"]\n",
    "y_data = df.loc[:, \"index_value\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape, x_train.size\n",
    "# clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "#                    hidden_layer_sizes=(6, 6), random_state=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in pd.read_csv(<filepath>, chunksize=<your_chunksize_here>)\n",
    "#     do_processing()\n",
    "#     train_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def iter_minibatches(chunksize):\n",
    "#     # Provide chunks one by one\n",
    "#     chunkstartmarker = 0\n",
    "#     while chunkstartmarker < numtrainingpoints:\n",
    "#         chunkrows = range(chunkstartmarker,chunkstartmarker+chunksize)\n",
    "#         X_chunk, y_chunk = getrows(chunkrows)\n",
    "#         yield X_chunk, y_chunk\n",
    "#         chunkstartmarker += chunksize\n",
    "        \n",
    "\n",
    "\n",
    "# for j in range(0,100):\n",
    "#     for i in range(0, x_train.size):\n",
    "#        input_inst = x_train[[i]]\n",
    "#        target_inst= y_train[[i]]\n",
    "\n",
    "#        clf=clf.partial_fit(input_inst,target_inst)\n",
    "    \n",
    "\n",
    "\n",
    "# # 3. Monitor progress\n",
    "# print(\"Score on training set: %0.8f\" % clf.score(x_train, y_train))\n",
    "# #Testing the Neural Net\n",
    "# y_pred = clf.predict(x_test)\n",
    "# print(y_pred)\n",
    "\n",
    "# # 4. Compute score on testing set\n",
    "# print(clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x_train_norm = preprocessing.scale(x_train)\n",
    "print(x_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(6, 6), random_state=1)\n",
    "\n",
    "# Partial fit only available with stochastic\n",
    "# clf = MLPClassifier(solver='stochastic', alpha=1e-5,\n",
    "#                    hidden_layer_sizes=(5, 2), random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm[:500], y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train_norm[:6000], y_train[:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_norm = preprocessing.scale(x_test)\n",
    "y_pred = clf.predict(x_test[:6000])\n",
    "# y_test_norm = preprocessing.scale(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test[:6000], y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test_norm[:6000], y_test[:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_train_norm[:6000])\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mean_squared_error(y_train[:6000], y_pred))\n",
    "print(precision_score(y_train[:6000], y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'postgresql://{user}:{passwd}@{host}:{port}/{db}'.format(\n",
    "         user=\"cse6242\", passwd=\"cse6242\", host=\"localhost\", port=5432, db=\"cse6242\")\n",
    "\n",
    "engine = create_engine(url, pool_size=50)\n",
    "\n",
    "engine.connect()\n",
    "connection = engine.connect() \n",
    "query = \"SELECT county_id, home_type_id, year_month, index_value from county_timeseries\"\n",
    "\n",
    "df = pd.read_sql(query, con=connection)\n",
    "\n",
    "df.rename(columns = {'year_month':'year'}, inplace = True)\n",
    "df[['year','month']] = df['year'].str.split('-',expand=True)\n",
    "\n",
    "cols = df.columns.tolist() \n",
    "new_cols = [x for x in cols if x != cols[-2]] + [cols[-2]]\n",
    "df = df[new_cols]\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.fillna(method=\"bfill\", inplace=True)\n",
    "random_state = 100\n",
    "x_data = df.loc[:, df.columns != \"index_value\"]\n",
    "y_data = df.loc[:, \"index_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, x_vals, y_vals\n",
    "\n",
    "random_state = 100\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1745721, 4), (581907, 4), (1745721,), (581907,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_regr = LinearRegression()\n",
    "\n",
    "lin_regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153670.65202356884\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = lin_regr.predict(x_train)\n",
    "print(sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157700.6380330208\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = lin_regr.predict(x_test)\n",
    "print(sqrt(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>07</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>08</td>\n",
       "      <td>95300.0</td>\n",
       "      <td>256501.385385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>09</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>256778.585998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>95400.0</td>\n",
       "      <td>257055.786611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>257332.987224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>02</td>\n",
       "      <td>101200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>03</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>255392.582932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>05</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>255669.783546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>06</td>\n",
       "      <td>97400.0</td>\n",
       "      <td>255946.984159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_id  home_type_id  year month  index_value         y_pred\n",
       "0              273             7  2011    07      96000.0            NaN\n",
       "1              273             7  2011    08      95300.0  256501.385385\n",
       "2              273             7  2011    09      95200.0  256778.585998\n",
       "3              273             7  2011    10      95400.0  257055.786611\n",
       "4              273             7  2011    11      95900.0  257332.987224\n",
       "...            ...           ...   ...   ...          ...            ...\n",
       "2327623        273             7  2011    02     101200.0            NaN\n",
       "2327624        273             7  2011    03     100800.0            NaN\n",
       "2327625        273             7  2011    04     100000.0  255392.582932\n",
       "2327626        273             7  2011    05      98800.0  255669.783546\n",
       "2327627        273             7  2011    06      97400.0  255946.984159\n",
       "\n",
       "[2327628 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hats_df = pd.DataFrame(data = y_pred_train, columns = ['y_pred'], index = x_train.index.copy())\n",
    "df_out_lin_regr_train = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(df_out_lin_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>07</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>256224.184772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>08</td>\n",
       "      <td>95300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>09</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>95400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>02</td>\n",
       "      <td>101200.0</td>\n",
       "      <td>254838.181706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>03</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>255115.382319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>05</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>06</td>\n",
       "      <td>97400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_id  home_type_id  year month  index_value         y_pred\n",
       "0              273             7  2011    07      96000.0  256224.184772\n",
       "1              273             7  2011    08      95300.0            NaN\n",
       "2              273             7  2011    09      95200.0            NaN\n",
       "3              273             7  2011    10      95400.0            NaN\n",
       "4              273             7  2011    11      95900.0            NaN\n",
       "...            ...           ...   ...   ...          ...            ...\n",
       "2327623        273             7  2011    02     101200.0  254838.181706\n",
       "2327624        273             7  2011    03     100800.0  255115.382319\n",
       "2327625        273             7  2011    04     100000.0            NaN\n",
       "2327626        273             7  2011    05      98800.0            NaN\n",
       "2327627        273             7  2011    06      97400.0            NaN\n",
       "\n",
       "[2327628 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hats_df = pd.DataFrame(data = y_pred_test, columns = ['y_pred'], index = x_test.index.copy())\n",
    "df_out_lin_regr_test = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(df_out_lin_regr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>07</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>256224.184772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>08</td>\n",
       "      <td>95300.0</td>\n",
       "      <td>256501.385385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>09</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>256778.585998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>95400.0</td>\n",
       "      <td>257055.786611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>257332.987224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>02</td>\n",
       "      <td>101200.0</td>\n",
       "      <td>254838.181706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>03</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>255115.382319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>255392.582932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>05</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>255669.783546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>06</td>\n",
       "      <td>97400.0</td>\n",
       "      <td>255946.984159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_id  home_type_id  year month  index_value         y_pred\n",
       "0              273             7  2011    07      96000.0  256224.184772\n",
       "1              273             7  2011    08      95300.0  256501.385385\n",
       "2              273             7  2011    09      95200.0  256778.585998\n",
       "3              273             7  2011    10      95400.0  257055.786611\n",
       "4              273             7  2011    11      95900.0  257332.987224\n",
       "...            ...           ...   ...   ...          ...            ...\n",
       "2327623        273             7  2011    02     101200.0  254838.181706\n",
       "2327624        273             7  2011    03     100800.0  255115.382319\n",
       "2327625        273             7  2011    04     100000.0  255392.582932\n",
       "2327626        273             7  2011    05      98800.0  255669.783546\n",
       "2327627        273             7  2011    06      97400.0  255946.984159\n",
       "\n",
       "[2327628 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df_out = df_out_lin_regr_train['y_pred'].combine_first(df_out_lin_regr_test['y_pred'])\n",
    "\n",
    "y_hats_df = pd.DataFrame(data = final_df_out, columns = ['y_pred'], index = df.index.copy())\n",
    "final_df_out = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(final_df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = pd.DataFrame(data={\"county_id\": [], \"home_type_id\": [], \"year_month\": [], \"index_value\": [], \"year\": [], \"month\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ids = df[\"county_id\"].unique()\n",
    "home_type_ids = df[\"home_type_id\"].unique()\n",
    "month_ids = df[\"month\"].unique()\n",
    "future_years = [x for x in range(2019, 2025)]\n",
    "\n",
    "index = pd.MultiIndex.from_product([county_ids, home_type_ids, month_ids, future_years], names = [\"county_ids\", \"home_type_ids\", \"month_ids\", \"future_years\"])\n",
    "# Dataframe to predict results\n",
    "prediction_df = pd.DataFrame(index = index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df[\"index_values\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sys, os\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "url = 'postgresql://{user}:{passwd}@{host}:{port}/{db}'.format(\n",
    "         user=\"cse6242\", passwd=\"cse6242\", host=\"localhost\", port=5432, db=\"cse6242\")\n",
    "\n",
    "engine = create_engine(url, pool_size=50)\n",
    "\n",
    "engine.connect()\n",
    "connection = engine.connect() \n",
    "query = \"SELECT county_id, home_type_id, year_month, index_value from county_timeseries\"\n",
    "\n",
    "df = pd.read_sql(query, con=connection)\n",
    "\n",
    "df.rename(columns = {'year_month':'year'}, inplace = True)\n",
    "df[['year','month']] = df['year'].str.split('-',expand=True)\n",
    "\n",
    "cols = df.columns.tolist() \n",
    "new_cols = [x for x in cols if x != cols[-2]] + [cols[-2]]\n",
    "df = df[new_cols]\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.fillna(method=\"bfill\", inplace=True)\n",
    "random_state = 100\n",
    "x_data = df.loc[:, df.columns != \"index_value\"]\n",
    "y_data = df.loc[:, \"index_value\"]\n",
    "\n",
    "\n",
    "random_state = 100\n",
    "x_data = df.loc[:, df.columns != \"index_value\"]\n",
    "y_data = df.loc[:, \"index_value\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, shuffle=True, random_state=random_state)\n",
    "\n",
    "\n",
    "# print(x_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, random_state=0,\n",
    "                             n_estimators=100)\n",
    "\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_random_forest_train = sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498.8060009076316\n"
     ]
    }
   ],
   "source": [
    "print(rmse_random_forest_train)  # 154732.57953090698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>07</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>08</td>\n",
       "      <td>95300.0</td>\n",
       "      <td>95485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>09</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>95378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>95400.0</td>\n",
       "      <td>95575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>95907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>02</td>\n",
       "      <td>101200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>03</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>05</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>06</td>\n",
       "      <td>97400.0</td>\n",
       "      <td>96716.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_id  home_type_id  year month  index_value   y_pred\n",
       "0              273             7  2011    07      96000.0      NaN\n",
       "1              273             7  2011    08      95300.0  95485.0\n",
       "2              273             7  2011    09      95200.0  95378.0\n",
       "3              273             7  2011    10      95400.0  95575.0\n",
       "4              273             7  2011    11      95900.0  95907.0\n",
       "...            ...           ...   ...   ...          ...      ...\n",
       "2327623        273             7  2011    02     101200.0      NaN\n",
       "2327624        273             7  2011    03     100800.0      NaN\n",
       "2327625        273             7  2011    04     100000.0      NaN\n",
       "2327626        273             7  2011    05      98800.0      NaN\n",
       "2327627        273             7  2011    06      97400.0  96716.0\n",
       "\n",
       "[2327628 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hats_df = pd.DataFrame(data = y_pred, columns = ['y_pred'], index = x_train.index.copy())\n",
    "df_out_random_forest_train = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(df_out_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr_test = RandomForestRegressor(max_depth=None, random_state=0,\n",
    "#                              n_estimators=100)\n",
    "\n",
    "\n",
    "# regr.fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_random_forest_test = sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7304.665032087787\n"
     ]
    }
   ],
   "source": [
    "print(rmse_random_forest_test)  # 153347.29729014944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>07</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>96737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>08</td>\n",
       "      <td>95300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>09</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>95400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>02</td>\n",
       "      <td>101200.0</td>\n",
       "      <td>97988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>03</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>97697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>97254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>05</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>96818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>06</td>\n",
       "      <td>97400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_id  home_type_id  year month  index_value   y_pred\n",
       "0              273             7  2011    07      96000.0  96737.0\n",
       "1              273             7  2011    08      95300.0      NaN\n",
       "2              273             7  2011    09      95200.0      NaN\n",
       "3              273             7  2011    10      95400.0      NaN\n",
       "4              273             7  2011    11      95900.0      NaN\n",
       "...            ...           ...   ...   ...          ...      ...\n",
       "2327623        273             7  2011    02     101200.0  97988.0\n",
       "2327624        273             7  2011    03     100800.0  97697.0\n",
       "2327625        273             7  2011    04     100000.0  97254.0\n",
       "2327626        273             7  2011    05      98800.0  96818.0\n",
       "2327627        273             7  2011    06      97400.0      NaN\n",
       "\n",
       "[2327628 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hats_df = pd.DataFrame(data = y_pred, columns = ['y_pred'], index = x_test.index.copy())\n",
    "df_out_random_forest_test = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(df_out_random_forest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_out_random_forest_train.merge(df_out_random_forest_test, how=\"inner\", left_on=[\"y_pred\"], right_on=[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          96737.0\n",
       "1          95485.0\n",
       "2          95378.0\n",
       "3          95575.0\n",
       "4          95907.0\n",
       "            ...   \n",
       "2327623    97988.0\n",
       "2327624    97697.0\n",
       "2327625    97254.0\n",
       "2327626    96818.0\n",
       "2327627    96716.0\n",
       "Name: y_pred, Length: 2327628, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df_out = df_out_random_forest_train['y_pred'].combine_first(df_out_random_forest_test['y_pred'])\n",
    "\n",
    "display(final_df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>97988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>97697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>97254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>96818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>96716.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_pred\n",
       "0        96737.0\n",
       "1        95485.0\n",
       "2        95378.0\n",
       "3        95575.0\n",
       "4        95907.0\n",
       "...          ...\n",
       "2327623  97988.0\n",
       "2327624  97697.0\n",
       "2327625  97254.0\n",
       "2327626  96818.0\n",
       "2327627  96716.0\n",
       "\n",
       "[2327628 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_id</th>\n",
       "      <th>home_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>index_value</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>07</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>96737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>08</td>\n",
       "      <td>95300.0</td>\n",
       "      <td>95485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>09</td>\n",
       "      <td>95200.0</td>\n",
       "      <td>95378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>95400.0</td>\n",
       "      <td>95575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>95907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327623</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>02</td>\n",
       "      <td>101200.0</td>\n",
       "      <td>97988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327624</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>03</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>97697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327625</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>97254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327626</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>05</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>96818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327627</th>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>06</td>\n",
       "      <td>97400.0</td>\n",
       "      <td>96716.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_id  home_type_id  year month  index_value   y_pred\n",
       "0              273             7  2011    07      96000.0  96737.0\n",
       "1              273             7  2011    08      95300.0  95485.0\n",
       "2              273             7  2011    09      95200.0  95378.0\n",
       "3              273             7  2011    10      95400.0  95575.0\n",
       "4              273             7  2011    11      95900.0  95907.0\n",
       "...            ...           ...   ...   ...          ...      ...\n",
       "2327623        273             7  2011    02     101200.0  97988.0\n",
       "2327624        273             7  2011    03     100800.0  97697.0\n",
       "2327625        273             7  2011    04     100000.0  97254.0\n",
       "2327626        273             7  2011    05      98800.0  96818.0\n",
       "2327627        273             7  2011    06      97400.0  96716.0\n",
       "\n",
       "[2327628 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hats_df = pd.DataFrame(data = final_df_out, columns = ['y_pred'], index = df.index.copy())\n",
    "display(y_hats_df)\n",
    "final_df_out = pd.merge(df, y_hats_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "display(final_df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
